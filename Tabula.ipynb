{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "279ac4ee-a5bf-40b5-9f2a-2c536a1326a3",
      "metadata": {
        "id": "279ac4ee-a5bf-40b5-9f2a-2c536a1326a3"
      },
      "outputs": [],
      "source": [
        "# optional setup; use if the notebook is not running inside the rtfm conda environment\n",
        "!git clone https://github.com/mlfoundations/rtfm.git\n",
        "%cd rtfm\n",
        "\n",
        "# Ensure pip is up to date\n",
        "!pip install --upgrade pip\n",
        "\n",
        "# Install Python 3.8 using pip\n",
        "!pip install python==3.8\n",
        "\n",
        "# Install pip dependencies from requirements.txt\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "# Install additional dependencies\n",
        "!pip install git+https://github.com/jpgard/llama-recipes.git\n",
        "!pip install -e .\n",
        "!pip install --no-deps git+https://github.com/mlfoundations/tableshift.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "49c5848f",
        "outputId": "b673c5e9-3a2d-4c75-c9ec-46c7f242737a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/lydia/.local/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "# change tabula to tabula_middle_padding to test middle padding method\n",
        "from tabula import Tabula\n",
        "import pandas as pd"
      ],
      "id": "49c5848f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e438a14b"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"Real_Datasets/Insurance_compressed.csv\")"
      ],
      "id": "e438a14b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5f700ed"
      },
      "outputs": [],
      "source": [
        "categorical_columns = [\"sex\", \"children\", \"sm\", \"region\"]\n",
        "model = Tabula(llm='distilgpt2', experiment_dir = \"insurance_training\", batch_size=32, epochs=400, categorical_columns = categorical_columns)"
      ],
      "id": "f5f700ed"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "837b11c0",
        "outputId": "d4f57e52-03c4-4e79-f391-d9232fa9d4c6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/lydia/.local/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 1338\n",
            "  Num Epochs = 400\n",
            "  Instantaneous batch size per device = 32\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 16800\n",
            "  Number of trainable parameters = 81912576\n",
            "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='16800' max='16800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [16800/16800 12:52, Epoch 400/400]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.839500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>1.010900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.812700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.725600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.683100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.659800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.644000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.631900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.623500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.615600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.608900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.603600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.599300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.594500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.591300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.587700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>0.583800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.581100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>0.578800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>0.575700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10500</td>\n",
              "      <td>0.574400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11000</td>\n",
              "      <td>0.571500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11500</td>\n",
              "      <td>0.569800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12000</td>\n",
              "      <td>0.567300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12500</td>\n",
              "      <td>0.565400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13000</td>\n",
              "      <td>0.563900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13500</td>\n",
              "      <td>0.562100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14000</td>\n",
              "      <td>0.561400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14500</td>\n",
              "      <td>0.559500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15000</td>\n",
              "      <td>0.558000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15500</td>\n",
              "      <td>0.556600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16000</td>\n",
              "      <td>0.555900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16500</td>\n",
              "      <td>0.554600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tabula.tabula_trainer.TabulaTrainer at 0x7f1961ded720>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(data)"
      ],
      "id": "837b11c0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cb7d3e08"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.save(model.model.state_dict(), \"insurance_training/model_400epoch.pt\")"
      ],
      "id": "cb7d3e08"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3b743035",
        "outputId": "bd216139-994b-4b8c-a93e-c6465a88f506"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|                                                                                          | 0/1338 [00:00<?, ?it/s]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "  7%|█████▉                                                                          | 99/1338 [00:00<00:05, 236.38it/s]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            " 15%|███████████▌                                                                   | 196/1338 [00:00<00:03, 341.89it/s]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            " 22%|█████████████████▏                                                             | 291/1338 [00:00<00:02, 388.87it/s]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            " 27%|█████████████████████▏                                                         | 359/1338 [00:01<00:02, 365.14it/s]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            " 34%|██████████████████████████▊                                                    | 455/1338 [00:01<00:02, 399.97it/s]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            " 39%|██████████████████████████████▊                                                | 522/1338 [00:01<00:02, 370.31it/s]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            " 45%|███████████████████████████████████▏                                           | 597/1338 [00:01<00:02, 366.52it/s]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            " 52%|█████████████████████████████████████████▏                                     | 697/1338 [00:01<00:01, 414.61it/s]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            " 59%|██████████████████████████████████████████████▉                                | 795/1338 [00:01<00:01, 474.93it/s]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            " 67%|████████████████████████████████████████████████████▌                          | 891/1338 [00:02<00:00, 462.04it/s]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            " 72%|█████████████████████████████████████████████████████████▎                     | 970/1338 [00:02<00:00, 428.75it/s]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            " 80%|██████████████████████████████████████████████████████████████▍               | 1070/1338 [00:02<00:00, 491.96it/s]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            " 87%|████████████████████████████████████████████████████████████████████          | 1168/1338 [00:02<00:00, 488.74it/s]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            " 95%|█████████████████████████████████████████████████████████████████████████▊    | 1267/1338 [00:02<00:00, 488.49it/s]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "100%|█████████████████████████████████████████████████████████████████████████████▊| 1335/1338 [00:03<00:00, 436.38it/s]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "1435it [00:03, 418.76it/s]                                                                                              \n"
          ]
        }
      ],
      "source": [
        "synthetic_data = model.sample(n_samples=1338)\n",
        "synthetic_data.to_csv(\"insurance_400epoch.csv\", index=False)"
      ],
      "id": "3b743035"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43f166f8",
        "outputId": "c3e89516-445e-4c52-f33a-37d3f25b2658"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "_IncompatibleKeys(missing_keys=['transformer.h.0.attn.bias', 'transformer.h.0.attn.masked_bias', 'transformer.h.1.attn.bias', 'transformer.h.1.attn.masked_bias', 'transformer.h.2.attn.bias', 'transformer.h.2.attn.masked_bias', 'transformer.h.3.attn.bias', 'transformer.h.3.attn.masked_bias', 'transformer.h.4.attn.bias', 'transformer.h.4.attn.masked_bias', 'transformer.h.5.attn.bias', 'transformer.h.5.attn.masked_bias'], unexpected_keys=[])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Comment this block out to test tabula starting from randomly initialized model.\n",
        "# Comment this block out when uses tabula_middle_padding\n",
        "import torch\n",
        "model.model.load_state_dict(torch.load(\"pretrained-model/model.pt\"), strict=False)"
      ],
      "id": "43f166f8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "initial_id",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-28T20:04:12.934625Z",
          "start_time": "2024-06-28T20:03:42.468103Z"
        },
        "colab": {
          "referenced_widgets": [
            "017a0900093145a3a8d3cae3e2d389e9"
          ]
        },
        "id": "initial_id",
        "outputId": "b3654019-0de2-4845-bc7e-d24be333eb5d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "read user yaml files: 0it [00:00, ?it/s]\n",
            "/gscratch/efml/jpgard/miniconda3/envs/rtfm/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "017a0900093145a3a8d3cae3e2d389e9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "WARNING:root:adding special tokens {} to vocab\n",
            "WARNING:root:adding tokens {'eoc_token': '<|endcompletion|>', 'qa_sep_token': '<|endinput|>', 'ans_choices_sep_token': '||'} to vocab (as special tokens=True\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoTokenizer, LlamaForCausalLM, AutoConfig\n",
        "\n",
        "from rtfm.configs import TrainConfig, TokenizerConfig\n",
        "from rtfm.inference_utils import InferenceModel\n",
        "from rtfm.serialization.serializers import get_serializer\n",
        "from rtfm.tokenization.text import prepare_tokenizer\n",
        "\n",
        "train_config = TrainConfig(model_name=\"mlfoundations/tabula-8b\", context_length=8192)\n",
        "\n",
        "# If using a base llama model (not fine-tuned TabuLa),\n",
        "# make sure to set add_serializer_tokens=False\n",
        "# (because we do not want to use special tokens for\n",
        "# the base model which is not trained on them).\n",
        "tokenizer_config = TokenizerConfig()\n",
        "\n",
        "# Load the configuration\n",
        "config = AutoConfig.from_pretrained(train_config.model_name)\n",
        "\n",
        "# Set the torch_dtype to bfloat16 which matches TabuLa train/eval setup\n",
        "config.torch_dtype = 'bfloat16'\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = LlamaForCausalLM.from_pretrained(\n",
        "    train_config.model_name, device_map=\"auto\", config=config).to(device)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(train_config.model_name)\n",
        "serializer = get_serializer(train_config.serializer_cls)\n",
        "\n",
        "tokenizer, model = prepare_tokenizer(\n",
        "    model,\n",
        "    tokenizer=tokenizer,\n",
        "    pretrained_model_name_or_path=train_config.model_name,\n",
        "    model_max_length=train_config.context_length,\n",
        "    use_fast_tokenizer=tokenizer_config.use_fast_tokenizer,\n",
        "    serializer_tokens_embed_fn=tokenizer_config.serializer_tokens_embed_fn,\n",
        "    serializer_tokens=serializer.special_tokens\n",
        "    if tokenizer_config.add_serializer_tokens\n",
        "    else None,\n",
        ")\n",
        "\n",
        "inference_model = InferenceModel(model=model, tokenizer=tokenizer, serializer=serializer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7eb7965984ae881",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "d7eb7965984ae881"
      },
      "source": [
        "# Creating your own data for inference\n",
        "\n",
        "If you simply want to explore the model, or would like to construct your own data for inference, you can simply construct DataFrames to represent the labeled examples (\"shots\"), if any are used, and the target example that you want to predict on.\n",
        "\n",
        "Below is an example.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92fbaac767622695",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-28T20:04:39.766837Z",
          "start_time": "2024-06-28T20:04:12.941752Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "92fbaac767622695",
        "outputId": "20be87db-c204-49a8-96e6-4fa9b47057d2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction for sample \n",
            "    location  temperature  humidity  wind_speed  pressure month  \\\n",
            "0  San Jose           23        55           8      1013  July   \n",
            "\n",
            "  weather_yesterday  precipitation  visibility weather_today  \n",
            "0             Sunny              0          10         Sunny   \n",
            " is: Sunny\n"
          ]
        }
      ],
      "source": [
        "labeled_examples = pd.DataFrame(\n",
        "    [\n",
        "        {\"location\": \"New York\", \"temperature\": 22, \"humidity\": 65, \"wind_speed\": 12, \"pressure\": 1012, \"month\": \"July\",\n",
        "         \"weather_yesterday\": \"Sunny\", \"precipitation\": 0, \"visibility\": 10, \"weather_today\": \"Partly Sunny\"},\n",
        "        {\"location\": \"Los Angeles\", \"temperature\": 26, \"humidity\": 60, \"wind_speed\": 7, \"pressure\": 1015,\n",
        "         \"month\": \"July\", \"weather_yesterday\": \"Partly Sunny\", \"precipitation\": 0, \"visibility\": 10, \"weather_today\": \"Sunny\"},\n",
        "        {\"location\": \"Chicago\", \"temperature\": 18, \"humidity\": 70, \"wind_speed\": 15, \"pressure\": 1008, \"month\": \"July\",\n",
        "         \"weather_yesterday\": \"Partly Cloudy\", \"precipitation\": 0.1, \"visibility\": 8, \"weather_today\": \"Cloudy\"},\n",
        "        {\"location\": \"Houston\", \"temperature\": 30, \"humidity\": 80, \"wind_speed\": 10, \"pressure\": 1010, \"month\": \"July\",\n",
        "         \"weather_yesterday\": \"Rain\", \"precipitation\": 0.5, \"visibility\": 7, \"weather_today\": \"Rain\"},\n",
        "        {\"location\": \"Phoenix\", \"temperature\": 35, \"humidity\": 20, \"wind_speed\": 5, \"pressure\": 1005, \"month\": \"July\",\n",
        "         \"weather_yesterday\": \"Sunny\", \"precipitation\": 0, \"visibility\": 10, \"weather_today\": \"Sunny\"},\n",
        "        {\"location\": \"Philadelphia\", \"temperature\": 24, \"humidity\": 75, \"wind_speed\": 14, \"pressure\": 1009,\n",
        "         \"month\": \"July\", \"weather_yesterday\": \"Partly Cloudy\", \"precipitation\": 0.2, \"visibility\": 9,\n",
        "         \"weather_today\": \"Partly Cloudy\"},\n",
        "        {\"location\": \"San Antonio\", \"temperature\": 28, \"humidity\": 68, \"wind_speed\": 11, \"pressure\": 1011,\n",
        "         \"month\": \"July\", \"weather_yesterday\": \"Rain\", \"precipitation\": 0.4, \"visibility\": 8, \"weather_today\": \"Rain\"},\n",
        "        {\"location\": \"San Diego\", \"temperature\": 22, \"humidity\": 65, \"wind_speed\": 10, \"pressure\": 1014,\n",
        "         \"month\": \"July\", \"weather_yesterday\": \"Sunny\", \"precipitation\": 0, \"visibility\": 10, \"weather_today\": \"Partly Sunny\"},\n",
        "        {\"location\": \"Dallas\", \"temperature\": 27, \"humidity\": 72, \"wind_speed\": 9, \"pressure\": 1007, \"month\": \"July\",\n",
        "         \"weather_yesterday\": \"Partly Cloudy\", \"precipitation\": 0.3, \"visibility\": 9, \"weather_today\": \"Cloudy\"},\n",
        "    ]\n",
        ")\n",
        "target_example = pd.DataFrame(\n",
        "    [\n",
        "        {\"location\": \"San Jose\", \"temperature\": 23, \"humidity\": 55, \"wind_speed\": 8, \"pressure\": 1013, \"month\": \"July\",\n",
        "         \"weather_yesterday\": \"Sunny\", \"precipitation\": 0, \"visibility\": 10, \"weather_today\": \"Sunny\"},\n",
        "    ]\n",
        ")\n",
        "\n",
        "output = inference_model.predict(\n",
        "    target_example=target_example,\n",
        "    target_colname=\"weather_today\",\n",
        "    target_choices=[\"Sunny\", \"Partly Sunny\", \"Cloudy\", \"Partly Cloudy\", \"Rain\"],\n",
        "    labeled_examples=labeled_examples,\n",
        ")\n",
        "print(f\"Prediction for sample \\n {target_example} \\n is: {output}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5697e998e9356e4",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "5697e998e9356e4"
      },
      "source": [
        "# Prediction with continuous targets\n",
        "\n",
        "TabuLa-8B is also trained to perform prediction on continuous targets. This is handled by bucketing the continuous inputs and treating these as categorical labels. Besides this bucketization step, the procedure is otherwise identical.\n",
        "\n",
        "In order to ensure best performance, it is important to ensure that your serialization of the continuous targets matches exactly the expected format used during TabuLa's training.\n",
        "\n",
        "Note that here we'll process the examples together to ensure the discretization is applied correctly, before splitting into train/target samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd6c86babaa9b907",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "dd6c86babaa9b907",
        "outputId": "9d0644a1-a8e8-4996-ff5c-9edeeb85744e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction for sample \n",
            "    location  size_sqft  bedrooms  bathrooms  age  lot_size_acres  garage  \\\n",
            "0  New York       1200         3          2   10            0.15    True   \n",
            "\n",
            "                price  \n",
            "0  greater than 850.0   \n",
            " is: between 700.0 and 750.0\n"
          ]
        }
      ],
      "source": [
        "from rtfm.serialization.serialization_utils import discretize_continuous_column\n",
        "\n",
        "examples = pd.DataFrame(\n",
        "    [\n",
        "    {\"location\": \"New York\", \"size_sqft\": 1200, \"bedrooms\": 3, \"bathrooms\": 2, \"age\": 10, \"lot_size_acres\": 0.15, \"garage\": True, \"price\": 850},\n",
        "    {\"location\": \"Los Angeles\", \"size_sqft\": 1500, \"bedrooms\": 4, \"bathrooms\": 3, \"age\": 8, \"lot_size_acres\": 0.25, \"garage\": True, \"price\": 950},\n",
        "    {\"location\": \"Chicago\", \"size_sqft\": 1300, \"bedrooms\": 3, \"bathrooms\": 2, \"age\": 15, \"lot_size_acres\": 0.2, \"garage\": False, \"price\": 700},\n",
        "    {\"location\": \"Houston\", \"size_sqft\": 1700, \"bedrooms\": 4, \"bathrooms\": 3, \"age\": 5, \"lot_size_acres\": 0.3, \"garage\": True, \"price\": 650},\n",
        "    {\"location\": \"Phoenix\", \"size_sqft\": 1600, \"bedrooms\": 3, \"bathrooms\": 2, \"age\": 7, \"lot_size_acres\": 0.25, \"garage\": True, \"price\": 750},\n",
        "    {\"location\": \"Philadelphia\", \"size_sqft\": 1400, \"bedrooms\": 3, \"bathrooms\": 2, \"age\": 12, \"lot_size_acres\": 0.18, \"garage\": False, \"price\": 600},\n",
        "    {\"location\": \"San Antonio\", \"size_sqft\": 1800, \"bedrooms\": 4, \"bathrooms\": 3, \"age\": 3, \"lot_size_acres\": 0.4, \"garage\": True, \"price\": 700},\n",
        "    {\"location\": \"San Diego\", \"size_sqft\": 1550, \"bedrooms\": 3, \"bathrooms\": 2, \"age\": 9, \"lot_size_acres\": 0.22, \"garage\": True, \"price\": 850},\n",
        "    {\"location\": \"Dallas\", \"size_sqft\": 1450, \"bedrooms\": 3, \"bathrooms\": 2, \"age\": 11, \"lot_size_acres\": 0.19, \"garage\": True, \"price\": 700},\n",
        "    {\"location\": \"San Jose\", \"size_sqft\": 1600, \"bedrooms\": 4, \"bathrooms\": 3, \"age\": 6, \"lot_size_acres\": 0.2, \"garage\": False, \"price\": 800},\n",
        "    {\"location\": \"Seattle\", \"size_sqft\": 1800, \"bedrooms\": 4, \"bathrooms\": 2, \"age\": 10, \"lot_size_acres\": 0.2, \"garage\": False, \"price\": 925},\n",
        "]\n",
        ")\n",
        "\n",
        "examples[\"price\"] = discretize_continuous_column(examples[\"price\"], num_buckets=4)\n",
        "target_choices = examples[\"price\"].unique().tolist()\n",
        "\n",
        "target_example = examples.iloc[[0]]\n",
        "labeled_examples = examples.iloc[1:]\n",
        "\n",
        "\n",
        "output = inference_model.predict(\n",
        "    target_example=target_example,\n",
        "    target_colname=\"price\",\n",
        "    target_choices=target_choices,\n",
        "    labeled_examples=labeled_examples,\n",
        ")\n",
        "print(f\"Prediction for sample \\n {target_example} \\n is: {output}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}